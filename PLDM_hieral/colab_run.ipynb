{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLDM TwoRooms (L1 vs L2)\n",
    "\n",
    "Upload the tarball created by `PLDM_hieral/colab_pack.sh`, or clone the repo manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d63272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "OUTPUT_ROOT = '/content/drive/MyDrive/PLDM_hieral'\n",
    "os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
    "print('Drive output root:', OUTPUT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd226449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "uploaded = files.upload()\n",
    "if uploaded:\n",
    "    tar_name = next(iter(uploaded))\n",
    "    os.system(f\"tar -xzf {tar_name}\")\n",
    "else:\n",
    "    print(\"No tarball uploaded. Clone the repo manually if needed.\")\n",
    "\n",
    "repo_root = \".\"\n",
    "if os.path.isdir(\"PLDM_hieral\"):\n",
    "    repo_root = \".\"\n",
    "elif os.path.isdir(\"PLDM/PLDM_hieral\"):\n",
    "    repo_root = \"PLDM\"\n",
    "if repo_root != \".\":\n",
    "    os.chdir(repo_root)\n",
    "print(\"Repo root:\", os.getcwd())\n",
    "\n",
    "# Optional:\n",
    "# !git clone <repo-url>\n",
    "# %cd PLDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f8380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install gdown\n",
    "!pip install arm_pytorch_utilities==0.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d3bf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ce6a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash -c \"cd pldm_envs/wall && bash presaved_datasets/download_all.sh\"\n",
    "!bash -c \"cd pldm_envs/wall && mkdir -p presaved_datasets/rendered\"\n",
    "!bash -c \"cd pldm_envs/wall && PYTHONPATH=../.. python render_images.py --input_path presaved_datasets/ds_size_634_no_images.npz --output_path presaved_datasets/rendered/ds_size_634.npz --config configs/good_quality_data.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7528cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python PLDM_hieral/run_tworooms_compare.py \\\n",
    "  --config_l1 PLDM_hieral/configs/tworooms_l1.yaml \\\n",
    "  --config_l2 PLDM_hieral/configs/tworooms_l2.yaml \\\n",
    "  --output_root {OUTPUT_ROOT} \\\n",
    "  --mode both \\\n",
    "  --epochs 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f8a0b0",
   "metadata": {},
   "source": [
    "Outputs are saved to Google Drive under `/content/drive/MyDrive/PLDM_hieral`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e31f9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs are already in Drive.\n",
    "!ls -la {OUTPUT_ROOT}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
